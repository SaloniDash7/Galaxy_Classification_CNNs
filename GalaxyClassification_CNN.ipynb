{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tensorflow.contrib.keras as keras\n",
    "import tensorflow.contrib.layers as layers\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "IMAGE_SIZE=424\n",
    "\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAINING=55000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_VALIDATION=6578\n",
    "batch_size=16\n",
    "training_iters=5000\n",
    "\n",
    "logs_path='/tmp/tensorflow/Galaxy_Classification'\n",
    "train_dir='/tmp/Galaxy_Classification_train'\n",
    "sess=tf.InteractiveSession()\n",
    "    \n",
    "def read_images(filename_queue):\n",
    "    class GalaxyZooRecord(object):\n",
    "        pass\n",
    "    result=GalaxyZooRecord()\n",
    "    \n",
    "    result.height=424\n",
    "    result.width=424\n",
    "    result.depth=3\n",
    "    image_bytes=result.height*result.width*result.depth\n",
    "    \n",
    "    reader=tf.WholeFileReader()\n",
    "    result.key,value=reader.read(filename_queue)\n",
    "    image_bytes=tf.decode_raw(value,tf.uint8)\n",
    "    \n",
    "    depth_major=tf.reshape(image_bytes,[result.depth,result.height,result.width])\n",
    "    result.uint8image=tf.transpose(depth_major,[1,2,0])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def read_labels(filename_queue):\n",
    "    reader=tf.TextLineReader()\n",
    "    key,value=reader.read(filename_queue)\n",
    "    record_defaults = [[0.0] for _ in range(37)]\n",
    "    label=tf.stack(tf.decode_csv(value,record_defaults=record_defaults))\n",
    "    return label\n",
    "    \n",
    "def generate_training_data(batch_size):\n",
    "    images_filenames=[os.path.join(root,name) for root,dirs,files in os.walk('images_training') for name in files]\n",
    "    images_filename_queue=tf.train.string_input_producer(images_filenames)\n",
    "    \n",
    "    read_input=read_images(images_filename_queue)\n",
    "    reshaped_image=tf.cast(read_input.uint8image,tf.float32)\n",
    "    height=IMAGE_SIZE\n",
    "    width=IMAGE_SIZE\n",
    "    \n",
    "    cropped_image=tf.image.central_crop(reshaped_image,0.5)\n",
    "    resized_image=tf.image.resize_images(cropped_image,[90,90])\n",
    "    \n",
    "    rotated_image=tf.contrib.image.rotate(resized_image,random.uniform(0,math.pi))\n",
    "    \n",
    "    distorted_image=tf.image.random_flip_left_right(rotated_image)\n",
    "    distorted_image=tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image=tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    distorted_image=tf.image.central_crop(distorted_image,0.5)\n",
    "   \n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "    float_image.set_shape([45, 45, 3])\n",
    "\n",
    "    labels_filename_queue=tf.train.string_input_producer([\"training_solutions.csv\"],shuffle=False)\n",
    "    label=read_labels(labels_filename_queue)\n",
    "    coord=tf.train.Coordinator()\n",
    "    threads=tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    min_queue_examples=int(0.5*NUM_EXAMPLES_PER_EPOCH_FOR_TRAINING)\n",
    "    print ('Filling queue with %d GalaxyZoo examples before starting to train. ' 'This will take a few minutes.' % min_queue_examples)\n",
    "    \n",
    "    return _generate_image_and_labels_batch(float_image,label,min_queue_examples,batch_size)\n",
    "\n",
    "def _generate_image_and_labels_batch(image,label,min_queue_examples,batch_size):\n",
    "    num_preprocess_threads = 16\n",
    "    images,labels=tf.train.batch([image,label],batch_size=batch_size,num_threads=num_preprocess_threads,capacity=min_queue_examples+3*batch_size)\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images,labels\n",
    "    \n",
    "images,labels=generate_training_data(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE CONVOLUTIONAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_summaries(x):\n",
    "    #Creates a summary that provides a histogram of activations\n",
    "    #Creates a summary that measures the sparsity of activations\n",
    "    tf.summary.histogram('Activations',x)\n",
    "    tf.summary.scalar('Sparsity',tf.nn.zero_fraction(x)) # Returns faction of zeros in value\n",
    "\n",
    "\n",
    "def ConVNet(images):\n",
    "    #Conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel=tf.get_variable('weights', shape=[6,6,3,32],dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.01,dtype=tf.float32),regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.0)))\n",
    "        conv=tf.nn.conv2d(images,kernel,[1,1,1,1],padding='VALID')\n",
    "        biases=tf.get_variable('biases',[32],initializer=tf.constant_initializer(0.1))\n",
    "        conv1=tf.nn.relu(tf.nn.bias_add(conv,biases),name=scope.name)\n",
    "        activation_summaries(conv1)\n",
    "        \n",
    "    \n",
    "    #Conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel=tf.get_variable('weights', shape=[5,5,32,64],dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.01,dtype=tf.float32),regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.01)))\n",
    "        conv=tf.nn.conv2d(conv1,kernel,[1,1,1,1],padding='VALID')\n",
    "        biases=tf.get_variable('biases',[64],initializer=tf.constant_initializer(0.1))\n",
    "        conv2=tf.nn.relu(tf.nn.bias_add(conv,biases),name=scope.name)\n",
    "        activation_summaries(conv2)\n",
    "    #pool2\n",
    "    pool2=tf.nn.max_pool(conv2,ksize=[1,20,20,1],strides=[1,1,1,1],padding='VALID',name='pool2')\n",
    "    \n",
    "    \n",
    "    #Conv3\n",
    "    with tf.variable_scope('conv3') as scope:\n",
    "        kernel=tf.get_variable('weights', shape=[3,3,64,128],dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.01,dtype=tf.float32),regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.01)))\n",
    "        conv=tf.nn.conv2d(pool2,kernel,[1,1,1,1],padding='VALID')\n",
    "        biases=tf.get_variable('biases',[128],initializer=tf.constant_initializer(0.1))\n",
    "        conv3=tf.nn.relu(tf.nn.bias_add(conv,biases),name=scope.name)\n",
    "        activation_summaries(conv3)\n",
    "    #pool3\n",
    "    pool3=tf.nn.max_pool(conv3,ksize=[1,8,8,1],strides=[1,1,1,1],padding='VALID',name='pool3')\n",
    "    \n",
    "    #Conv4\n",
    "    with tf.variable_scope('conv4') as scope:\n",
    "        kernel=tf.get_variable('weights', shape=[3,3,128,128],dtype=tf.float32,initializer=tf.truncated_normal_initializer(stddev=0.01,dtype=tf.float32),regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.01)))\n",
    "        conv=tf.nn.conv2d(pool3,kernel,[1,1,1,1],padding='VALID')\n",
    "        biases=tf.get_variable('biases',[128],initializer=tf.constant_initializer(0.1))\n",
    "        conv4=tf.nn.relu(tf.nn.bias_add(conv,biases),name=scope.name)\n",
    "        activation_summaries(conv4)\n",
    "    #pool4\n",
    "    pool4=tf.nn.max_pool(conv4,ksize=[1,2,2,1],strides=[1,1,1,1],padding='VALID',name='pool4')\n",
    "    pool4_flat=layers.flatten(pool4)\n",
    "    \n",
    "    \n",
    "    #FC1\n",
    "    fc1=layers.fully_connected(pool4_flat,num_outputs=2048,activation_fn=tf.nn.relu,\n",
    "                        normalizer_fn=layers.batch_norm,\n",
    "                        weights_initializer=tf.truncated_normal_initializer(stddev=0.001,dtype=tf.float32),\n",
    "                        biases_initializer=tf.constant_initializer(0.01))\n",
    "    fc1=layers.dropout(fc1,keep_prob=0.7)\n",
    "    \n",
    "    \n",
    "    #FC2\n",
    "    fc2=layers.fully_connected(fc1,num_outputs=2048,activation_fn=tf.nn.relu,\n",
    "                               weights_initializer=tf.truncated_normal_initializer(stddev=0.001,dtype=tf.float32),\n",
    "                               normalizer_fn=layers.batch_norm,\n",
    "                               biases_initializer=tf.constant_initializer(0.01))\n",
    "    fc2=layers.dropout(fc2,keep_prob=0.7)\n",
    "    \n",
    "    #Softmax Layer\n",
    "    softmax_linear=layers.fully_connected(fc2,num_outputs=37,activation_fn=tf.nn.softmax,\n",
    "                                weights_initializer=tf.truncated_normal_initializer(stddev=0.01,dtype=tf.float32),\n",
    "                                biases_initializer=tf.constant_initializer(0.1))\n",
    "    activation_summaries(softmax_linear)\n",
    "    \n",
    "    return softmax_linear\n",
    "\n",
    "logits=ConVNet(images)\n",
    "cost=tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(labels,logits))))\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "    \n",
    "def train():\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        step=0\n",
    "        loss_total=0\n",
    "        writer.add_graph(sess.graph)\n",
    "        \n",
    "        while(step<training_iters):\n",
    "            summary,_loss=sess.run([merged,optimizer,cost])\n",
    "            writer.add_summary(summary, step)\n",
    "            #Stores total loss in 100 iters \n",
    "            loss_total += loss\n",
    "            if(step%1==0):\n",
    "                print(\"Iter= \" + str(step) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total))\n",
    "                loss_total=0\n",
    "                saver.save(session,\"./Saver/model.ckpt\")\n",
    "                print(\"Model saved \")\n",
    "            step+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
